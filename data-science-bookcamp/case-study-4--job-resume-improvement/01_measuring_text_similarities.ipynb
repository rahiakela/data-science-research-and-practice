{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-measuring-text-similarities.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOO3HR1KxP2Pbuu/iEIO4dt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/data-science-research-and-practice/blob/main/data-science-bookcamp/case-study-4--job-resume-improvement/01_measuring_text_similarities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Measuring text similarities"
      ],
      "metadata": {
        "id": "CKQ3xygyzGoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we focus on a basic NLP problem: **measuring the similarity between two texts**. \n",
        "\n",
        "We will quickly discover a feasible solution that is not computationally efficient.\n",
        "We will then explore a series of numerical techniques for rapidly computing\n",
        "text similarities."
      ],
      "metadata": {
        "id": "fJsYonsIz1lJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "nEaM8U6Lz_Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "gtDg8Oyyz__L"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "TobbrwVl0CWF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Simple text comparison"
      ],
      "metadata": {
        "id": "tRYlC_k-0OTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose we want to compare three simple texts:\n",
        "\n",
        "```text\n",
        "text1—She sells seashells by the seashore\n",
        "text2—“Seashells! The seashells are on sale! By the seashore.”\n",
        "text3—She sells 3 seashells to John, who lives by the lake.\n",
        "```\n",
        "\n",
        "Our goal is to determine whether `text1` is more similar to `text2` or to `text3`.\n",
        "\n"
      ],
      "metadata": {
        "id": "sTg51MOn0QLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning texts to variables\n",
        "text1 = \"She sells seashells by the seashore.\"\n",
        "text2 = '\"Seashells! The seashells are on sale! By the seashore.\"'\n",
        "text3 = \"She sells 3 seashells to John, who lives by the lake.\""
      ],
      "metadata": {
        "id": "WCepvD5r0Wq4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to quantify the differences between texts."
      ],
      "metadata": {
        "id": "uvofbc7T05_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting texts into words\n",
        "words_lists = [text.split() for text in [text1, text2, text3]]\n",
        "words1, words2, words3 = words_lists\n",
        "\n",
        "for i, words in enumerate(words_lists, 1):\n",
        "  print(f\"Words in text {i}\")\n",
        "  print(f\"{words}\\n\")"
      ],
      "metadata": {
        "id": "9gsaUHqR06bp",
        "outputId": "87935885-60db-4490-a4fa-5488662338bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words in text 1\n",
            "['She', 'sells', 'seashells', 'by', 'the', 'seashore.']\n",
            "\n",
            "Words in text 2\n",
            "['\"Seashells!', 'The', 'seashells', 'are', 'on', 'sale!', 'By', 'the', 'seashore.\"']\n",
            "\n",
            "Words in text 3\n",
            "['She', 'sells', '3', 'seashells', 'to', 'John,', 'who', 'lives', 'by', 'the', 'lake.']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing case sensitivity and punctuation\n",
        "def simplify_text(text):\n",
        "  for punctuation in ['.', ',', '!', '?', '\"']:\n",
        "    text = text.replace(punctuation, \"\")\n",
        "  return text.lower()"
      ],
      "metadata": {
        "id": "SHYUPbuJ1gpZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, words in enumerate(words_lists, 1):\n",
        "  for j, word in enumerate(words):\n",
        "    words[j] = simplify_text(word)\n",
        "  print(f\"Words in text {i}\")\n",
        "  print(f\"{words}\\n\")"
      ],
      "metadata": {
        "id": "vxr_TPOa1yOj",
        "outputId": "0efa746d-2705-4ebf-ad4a-493ef237c5d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words in text 1\n",
            "['she', 'sells', 'seashells', 'by', 'the', 'seashore']\n",
            "\n",
            "Words in text 2\n",
            "['seashells', 'the', 'seashells', 'are', 'on', 'sale', 'by', 'the', 'seashore']\n",
            "\n",
            "Words in text 3\n",
            "['she', 'sells', '3', 'seashells', 'to', 'john', 'who', 'lives', 'by', 'the', 'lake']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting word lists to sets\n",
        "words_sets = [set(words) for words in words_lists]\n",
        "for i, unique_words in enumerate(words_sets, 1):\n",
        "  print(f\"Unique Words in text {i}\")\n",
        "  print(f\"{unique_words}\\n\")"
      ],
      "metadata": {
        "id": "37vWSeHg2hDE",
        "outputId": "4a970b10-02a5-41f7-e0e1-90e9fbba02c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Words in text 1\n",
            "{'by', 'she', 'the', 'seashore', 'sells', 'seashells'}\n",
            "\n",
            "Unique Words in text 2\n",
            "{'by', 'the', 'are', 'seashore', 'sale', 'on', 'seashells'}\n",
            "\n",
            "Unique Words in text 3\n",
            "{'by', '3', 'she', 'the', 'who', 'sells', 'lives', 'lake', 'john', 'seashells', 'to'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting overlapping words between two texts\n",
        "words_set1 = words_sets[0]\n",
        "for i, words_set in enumerate(words_sets[1:], 2):\n",
        "  shared_words = words_set1 & words_set\n",
        "  print(f\"Texts 1 and {i} share these {len(shared_words)} words:\")\n",
        "  print(f\"{shared_words}\\n\")"
      ],
      "metadata": {
        "id": "sVXOROoY6Eco",
        "outputId": "1dfc4b74-5892-499f-f26d-922b10ae98b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texts 1 and 2 share these 4 words:\n",
            "{'the', 'by', 'seashells', 'seashore'}\n",
            "\n",
            "Texts 1 and 3 share these 5 words:\n",
            "{'by', 'she', 'the', 'sells', 'seashells'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting diverging words between two texts\n",
        "for i, words_set in enumerate(words_sets[1:], 2):\n",
        "  diverging_words = words_set1 ^ words_set\n",
        "  print(f\"Texts 1 and {i} don't share these {len(diverging_words)} words:\")\n",
        "  print(f\"{diverging_words}\\n\")"
      ],
      "metadata": {
        "id": "rD7E9MVI7AD0",
        "outputId": "cb1e8c58-21ee-4041-dddc-2e5e11cb84c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texts 1 and 2 don't share these 5 words:\n",
            "{'she', 'are', 'sells', 'sale', 'on'}\n",
            "\n",
            "Texts 1 and 3 don't share these 7 words:\n",
            "{'3', 'seashore', 'who', 'lives', 'lake', 'john', 'to'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To combine their overlap and divergence into a single similarity score, we must first combine all overlapping\n",
        "and diverging words between the texts. \n",
        "\n",
        "This aggregation, which is called a union, will\n",
        "contain all the unique words across the two texts."
      ],
      "metadata": {
        "id": "pZklMwBh7Zur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the union of words between two texts\n",
        "for i, words_set in enumerate(words_sets[1:], 2):\n",
        "  total_words = words_set1 | words_set\n",
        "  print(f\"Together, texts 1 and {i} contain {len(total_words)} unique words. These words are:\\n {total_words}\\n\")"
      ],
      "metadata": {
        "id": "ZNeEwj1XH_sD",
        "outputId": "02aa1380-52f6-4365-9915-c28e0b78cc0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Together, texts 1 and 2 contain 9 unique words. These words are:\n",
            " {'by', 'seashore', 'she', 'the', 'are', 'sells', 'sale', 'on', 'seashells'}\n",
            "\n",
            "Together, texts 1 and 3 contain 12 unique words. These words are:\n",
            " {'by', 'seashore', 'the', 'who', 'lives', 'lake', 'to', '3', 'she', 'sells', 'john', 'seashells'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accordingly, both overlap and divergence represent complementary\n",
        "percentages of the total unique word count across texts."
      ],
      "metadata": {
        "id": "5iNostovIpvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the percentage of shared words between two texts\n",
        "for i, words_set in enumerate(words_sets[1:], 2):\n",
        "  shared_words = words_set1 & words_set\n",
        "  diverging_words = words_set1 ^ words_set\n",
        "  total_words = words_set1 | words_set\n",
        "  assert len(total_words) == len(shared_words) + len(diverging_words)\n",
        "\n",
        "  # Percent of total words shared with text 1\n",
        "  percent_shared = 100 * len(shared_words) / len(total_words)\n",
        "  # Percent of total words that diverge from text 1 \n",
        "  percent_diverging = 100 * len(diverging_words) / len(total_words)\n",
        "\n",
        "  print(f\"Together, texts 1 and {i} contain {len(total_words)} unique words. \\n{percent_shared:.2f}% of these words are shared.\\n{percent_diverging:.2f}% of these words diverge.\\n\")"
      ],
      "metadata": {
        "id": "NI-ab1ClIqOb",
        "outputId": "ac78fca0-2fd8-4769-9635-2f31846ac1c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Together, texts 1 and 2 contain 9 unique words. \n",
            "44.44% of these words are shared.\n",
            "55.56% of these words diverge.\n",
            "\n",
            "Together, texts 1 and 3 contain 12 unique words. \n",
            "41.67% of these words are shared.\n",
            "58.33% of these words diverge.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We’ve essentially developed a simple metric for assessing similarities between texts.\n",
        "\n",
        "This similarity metric is referred to as the Jaccard similarity, or the Jaccard index."
      ],
      "metadata": {
        "id": "ysjoVu4AKUhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exploring the Jaccard similarity"
      ],
      "metadata": {
        "id": "VTRCmi4XKLus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EJAW90_GKOc_"
      }
    }
  ]
}