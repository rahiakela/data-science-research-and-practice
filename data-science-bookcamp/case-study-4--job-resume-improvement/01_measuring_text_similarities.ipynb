{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-measuring-text-similarities.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMaPUytVLIkBDWT8wHrFDoC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/data-science-research-and-practice/blob/main/data-science-bookcamp/case-study-4--job-resume-improvement/01_measuring_text_similarities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Measuring text similarities"
      ],
      "metadata": {
        "id": "CKQ3xygyzGoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we focus on a basic NLP problem: **measuring the similarity between two texts**. \n",
        "\n",
        "We will quickly discover a feasible solution that is not computationally efficient.\n",
        "We will then explore a series of numerical techniques for rapidly computing\n",
        "text similarities."
      ],
      "metadata": {
        "id": "fJsYonsIz1lJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "nEaM8U6Lz_Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "gtDg8Oyyz__L"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "TobbrwVl0CWF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Simple text comparison"
      ],
      "metadata": {
        "id": "tRYlC_k-0OTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose we want to compare three simple texts:\n",
        "\n",
        "```text\n",
        "text1—She sells seashells by the seashore\n",
        "text2—“Seashells! The seashells are on sale! By the seashore.”\n",
        "text3—She sells 3 seashells to John, who lives by the lake.\n",
        "```\n",
        "\n",
        "Our goal is to determine whether `text1` is more similar to `text2` or to `text3`.\n",
        "\n"
      ],
      "metadata": {
        "id": "sTg51MOn0QLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning texts to variables\n",
        "text1 = \"She sells seashells by the seashore.\"\n",
        "text2 = '\"Seashells! The seashells are on sale! By the seashore.\"'\n",
        "text3 = \"She sells 3 seashells to John, who lives by the lake.\""
      ],
      "metadata": {
        "id": "WCepvD5r0Wq4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to quantify the differences between texts."
      ],
      "metadata": {
        "id": "uvofbc7T05_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting texts into words\n",
        "words_lists = [text.split() for text in [text1, text2, text3]]\n",
        "words1, words2, words3 = words_lists\n",
        "\n",
        "for i, words in enumerate(words_lists, 1):\n",
        "  print(f\"Words in text {i}\")\n",
        "  print(f\"{words}\\n\")"
      ],
      "metadata": {
        "id": "9gsaUHqR06bp",
        "outputId": "ebe33e6a-4819-4e9c-9175-e1e25f3511e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words in text 1\n",
            "['She', 'sells', 'seashells', 'by', 'the', 'seashore.']\n",
            "\n",
            "Words in text 2\n",
            "['\"Seashells!', 'The', 'seashells', 'are', 'on', 'sale!', 'By', 'the', 'seashore.\"']\n",
            "\n",
            "Words in text 3\n",
            "['She', 'sells', '3', 'seashells', 'to', 'John,', 'who', 'lives', 'by', 'the', 'lake.']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing case sensitivity and punctuation\n",
        "def simplify_text(text):\n",
        "  for punctuation in ['.', ',', '!', '?', '\"']:\n",
        "    text = text.replace(punctuation, \"\")\n",
        "  return text.lower()"
      ],
      "metadata": {
        "id": "SHYUPbuJ1gpZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, words in enumerate(words_lists, 1):\n",
        "  for j, word in enumerate(words):\n",
        "    words[j] = simplify_text(word)\n",
        "  print(f\"Words in text {i}\")\n",
        "  print(f\"{words}\\n\")"
      ],
      "metadata": {
        "id": "vxr_TPOa1yOj",
        "outputId": "f64c0bc9-8b4f-4983-e313-bbac94775822",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words in text 1\n",
            "['she', 'sells', 'seashells', 'by', 'the', 'seashore']\n",
            "\n",
            "Words in text 2\n",
            "['seashells', 'the', 'seashells', 'are', 'on', 'sale', 'by', 'the', 'seashore']\n",
            "\n",
            "Words in text 3\n",
            "['she', 'sells', '3', 'seashells', 'to', 'john', 'who', 'lives', 'by', 'the', 'lake']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting word lists to sets\n",
        "words_sets = [set(words) for words in words_lists]\n",
        "for i, unique_words in enumerate(words_sets, 1):\n",
        "  print(f\"Unique Words in text {i}\")\n",
        "  print(f\"{unique_words}\\n\")"
      ],
      "metadata": {
        "id": "37vWSeHg2hDE",
        "outputId": "33da6d69-9dfa-4a93-eeff-2688f158b291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Words in text 1\n",
            "{'she', 'sells', 'the', 'by', 'seashells', 'seashore'}\n",
            "\n",
            "Unique Words in text 2\n",
            "{'on', 'sale', 'the', 'are', 'by', 'seashells', 'seashore'}\n",
            "\n",
            "Unique Words in text 3\n",
            "{'she', 'to', 'lives', 'sells', 'the', 'by', 'seashells', 'lake', 'who', 'john', '3'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting overlapping words between two texts\n",
        "words_set1 = words_sets[0]\n",
        "for i, words_set in enumerate(words_sets[1:], 2):\n",
        "  shared_words = words_set1 & words_set\n",
        "  print(f\"Texts 1 and {i} share these {len(shared_words)} words:\")\n",
        "  print(f\"{shared_words}\\n\")"
      ],
      "metadata": {
        "id": "sVXOROoY6Eco",
        "outputId": "74ae73a6-bee9-407b-cbc1-da05c73e381c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texts 1 and 2 share these 4 words:\n",
            "{'by', 'seashells', 'seashore', 'the'}\n",
            "\n",
            "Texts 1 and 3 share these 5 words:\n",
            "{'she', 'the', 'sells', 'by', 'seashells'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting diverging words between two texts\n",
        "for i, words_set in enumerate(words_sets[1:], 2):\n",
        "  diverging_words = words_set1 ^ words_set\n",
        "  print(f\"Texts 1 and {i} don't share these {len(diverging_words)} words:\")\n",
        "  print(f\"{diverging_words}\\n\")"
      ],
      "metadata": {
        "id": "rD7E9MVI7AD0",
        "outputId": "b54d6bf9-b188-4352-da37-aa83fae3caa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texts 1 and 2 don't share these 5 words:\n",
            "{'on', 'sale', 'she', 'sells', 'are'}\n",
            "\n",
            "Texts 1 and 3 don't share these 7 words:\n",
            "{'to', 'lives', 'lake', 'seashore', 'who', 'john', '3'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To combine their overlap and divergence into a single similarity score, we must first combine all overlapping\n",
        "and diverging words between the texts. \n",
        "\n",
        "This aggregation, which is called a union, will\n",
        "contain all the unique words across the two texts."
      ],
      "metadata": {
        "id": "pZklMwBh7Zur"
      }
    }
  ]
}