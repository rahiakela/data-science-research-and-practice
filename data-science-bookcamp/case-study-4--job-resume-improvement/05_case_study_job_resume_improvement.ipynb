{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMKIl8QqatmsdiLZCLTdYhc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/data-science-research-and-practice/blob/main/data-science-bookcamp/case-study-4--job-resume-improvement/05_case_study_job_resume_improvement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Case Study: Job Resume Improvement"
      ],
      "metadata": {
        "id": "CKQ3xygyzGoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our goal is to extract common data science skills from the downloaded job postings.\n",
        "Then we’ll compare these skills to our resume to determine which skills are\n",
        "missing. \n",
        "\n",
        "We will do so as follows:\n",
        "\n",
        "1. Parse all text from the downloaded HTML files.\n",
        "2. Explore the parsed output to learn how job skills are described in online\n",
        "postings. We’ll pay particular attention to whether certain HTML tags are\n",
        "more associated with skill descriptions.\n",
        "3. Attempt to filter any irrelevant job postings from our dataset.\n",
        "4. Cluster job skills based on text similarity.\n",
        "5. Visualize the clusters using word clouds.\n",
        "6. Adjust clustering parameters, if necessary, to improve the visualized output.\n",
        "7. Compare the clustered skills to our resume to uncover missing skills."
      ],
      "metadata": {
        "id": "fJsYonsIz1lJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "nEaM8U6Lz_Fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bs4"
      ],
      "metadata": {
        "id": "vpAfzxRYh-Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "gtDg8Oyyz__L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from bs4 import BeautifulSoup as bs\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.display import display, HTML"
      ],
      "metadata": {
        "id": "TobbrwVl0CWF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "wget https://github.com/rahiakela/data-science-research-and-practice/raw/main/data-science-bookcamp/case-study-4--job-resume-improvement/job_postings.zip\n",
        "wget https://github.com/rahiakela/data-science-research-and-practice/raw/main/data-science-bookcamp/case-study-4--job-resume-improvement/resume.txt\n",
        "wget https://github.com/rahiakela/data-science-research-and-practice/raw/main/data-science-bookcamp/case-study-4--job-resume-improvement/table_of_contents.txt\n",
        "\n",
        "unzip -qq job_postings.zip\n",
        "rm -rf job_postings.zip"
      ],
      "metadata": {
        "id": "0ZbfU9_S1FP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extracting skills from job posting"
      ],
      "metadata": {
        "id": "tRYlC_k-0OTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's explore HTML files in the job_postings directory."
      ],
      "metadata": {
        "id": "sTg51MOn0QLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading HTML files\n",
        "html_contents = []\n",
        "for file_name in sorted(glob.glob(\"job_postings/*.html\")):\n",
        "  with open(file_name, \"r\") as f:\n",
        "    html_contents.append(f.read())\n",
        "print(f\"We have loaded {len(html_contents)} HTML files.\")"
      ],
      "metadata": {
        "id": "WCepvD5r0Wq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e884fc80-df73-40b0-e679-382beb947e32"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have loaded 1458 HTML files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parsing HTML files\n",
        "soup_objects = []\n",
        "for html in html_contents:\n",
        "  soup = bs(html)\n",
        "  assert soup.title is not None\n",
        "  assert soup.body is not None\n",
        "  soup_objects.append(soup)"
      ],
      "metadata": {
        "id": "9gsaUHqR06bp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking title and body texts for duplicates\n",
        "html_dict = {\"Title\": [], \"Body\": []}\n",
        "\n",
        "for soup in soup_objects:\n",
        "  title = soup.find(\"title\").text\n",
        "  body = soup.find(\"body\").text\n",
        "  html_dict[\"Title\"].append(title)\n",
        "  html_dict[\"Body\"].append(body)\n",
        "\n",
        "df_jobs = pd.DataFrame(html_dict)\n",
        "summary = df_jobs.describe()\n",
        "df_jobs.describe()"
      ],
      "metadata": {
        "id": "SHYUPbuJ1gpZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "f25207e5-6122-4abf-adb6-bf2105e3c0c1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                Title  \\\n",
              "count                            1458   \n",
              "unique                           1364   \n",
              "top     Data Scientist - New York, NY   \n",
              "freq                               13   \n",
              "\n",
              "                                                     Body  \n",
              "count                                                1458  \n",
              "unique                                               1458  \n",
              "top     Data Scientist - Beavercreek, OH\\nData Scienti...  \n",
              "freq                                                    1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-612effa8-67e8-4a0b-a909-dee10a36c119\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1458</td>\n",
              "      <td>1458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>1364</td>\n",
              "      <td>1458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Data Scientist - New York, NY</td>\n",
              "      <td>Data Scientist - Beavercreek, OH\\nData Scienti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-612effa8-67e8-4a0b-a909-dee10a36c119')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-612effa8-67e8-4a0b-a909-dee10a36c119 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-612effa8-67e8-4a0b-a909-dee10a36c119');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exploring the HTML"
      ],
      "metadata": {
        "id": "1U9IAaV4466-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start our exploration by rendering the HTML."
      ],
      "metadata": {
        "id": "38AE6WF4OcVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rendering the HTML of the first job posting\n",
        "assert len(set(html_contents)) == len(html_contents)\n",
        "\n",
        "display(HTML(html_contents[0]))"
      ],
      "metadata": {
        "id": "ANhKc1npf3HO",
        "outputId": "8ae115b9-27aa-4fc8-a751-9925f990ee11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<html><head><title>Data Scientist - Beavercreek, OH</title></head>\n",
              "<body><h2>Data Scientist - Beavercreek, OH</h2>\n",
              "<p><b>Data Scientist</b></p>\n",
              "<p><b>Position Overview:</b></p>\n",
              "<p>Centauri is looking for a detail oriented, motivated, and organized Data Scientist to work as part of a team to clean, analyze, and produce insightful reporting on government data. The ideal candidate is adept at using large data sets to find trends for intelligence reporting and will be proficient in process optimization and using models to test the effectiveness of different courses of action. They must have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and producing easily understood visuals to represent findings. Candidate will work closely with Data Managers and stakeholders to tailor their analysis to answer key questions. The candidate must have a strong understanding of Geographic Information Systems (GIS) and statistical analysis.</p>\n",
              "<p><b>Responsibilities:</b></p>\n",
              "<ul><li>Use statistical research methods to analyze datasets produced through multiple sources of intelligence production</li><li>Mine and analyze data from databases to answer key intelligence questions</li><li>Assess the effectiveness and accuracy of new data sources and data gathering techniques</li><li>Develop custom data models and algorithms to apply to data sets</li><li>Use predictive modeling to produce reporting about future trends based on historical data</li><li>Spatially analyze geographic data using GIS tools</li><li>Visualize findings in easily understood graphics and aesthetically appealing finished reports</li></ul><p><b>Qualifications for Data Scientist:</b></p>\n",
              "<ul><li>Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets</li><li>Experience in basic visualization methods, especially using tools such as Tableau, ggplot, and matplotlib</li><li>Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks</li><li>Knowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications</li></ul></body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rendering the HTML of the second job posting\n",
        "display(HTML(html_contents[1]))"
      ],
      "metadata": {
        "id": "gYHMlK_zO10_",
        "outputId": "fb02f247-cb52-46ff-a4db-61826a33604d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<html><head><title>Data Scientist - Seattle, WA 98101</title></head>\n",
              "<body><h2>Data Scientist - Seattle, WA 98101</h2>\n",
              "<div>Are you interested in being a part of an Artificial Intelligence Marketing (AIM) company that is transforming how B2C enterprises engage with their customers; improving customer experience, marketing throughput and for the first time directly optimizing key business KPIs? Do you want to join a startup company backed by the top firms in the venture capital and SaaS industries? Would you like to be part of a company that prides itself on being a meritocracy, where passion, innovation, integrity, and our customers are at the heart of all that we do?\n",
              "Then, consider joining us at Amplero, an Artificial Intelligence Marketing company that leverages machine learning and multi-armed bandit experimentation to dynamically test thousands of permutations to adaptively optimize every customer interaction and maximize customer lifetime value and loyalty.\n",
              "We are growing our customer base and are looking for Data Scientists to join our innovative and energetic team! This is a unique opportunity to both drive innovations for our technology and to realize their impact as you work closely with our client engagement teams to best leverage our scientific capabilities within the Amplero product for marketing optimization and customer insights.</div></br>\n",
              "As an Amplero Data Scientist you would:</div><ul><li>Interface with our internal engagement teams and clients to understand business questions, and perform analytical \"deep dives\" to develop relevant and interpretive insights in support of our client engagements</li><li>Smartly leverage appropriate technologies to answer tough questions or understand root causes of unexpected outcomes and statistical anomalies</li><li>Develop analysis tools which will influence both our products and clients; including python pipelines focused on the productization of data science and insights tools for marketing performance and optimization</li><li>Feature generation and selection from a wide variety of raw data types including time series and graphs</li><li>Work with the Amplero Product Team to provide ongoing feedback to the features and priorities most aligned with our clients' current and future needs to inform the product roadmap, test product hypotheses as well as to help plan the product lifecycle</li></ul><div>\n",
              "We'd love to hear from you if:</div><ul><li>You're an expert with data analysis and visualization tools including Python (including NumPy, SciPy, Pandas, scikit-learn) and other packages that enable data mining and machine learning</li><li>You have a proven track record of applying data science to solve difficult real-world business problems</li><li>You're familiar with areas of marketing data science where beyond-human scale, advanced experimentation and machine learning capabilities are used for achieving marketing performance, for example, DMP's in display advertising, Multivariate Testing, Statistical Significance Evaluation</li><li>You've got excellent written and verbal communication skills for team and customer interactions - specifically, you're a genius at communicating results and the value of complex technical solutions to a non-technical audience</li><div>\n",
              "</p></body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting bullets from the HTML\n",
        "df_jobs[\"Bullets\"] = [[bullet.text.strip() for bullet in soup.find_all(\"li\")] for soup in soup_objects]"
      ],
      "metadata": {
        "id": "6WKBkL30O74I"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Measuring the percent of bulleted postings\n",
        "bulleted_post_count = 0\n",
        "for bullet_list in df_jobs.Bullets:\n",
        "  if bullet_list:\n",
        "    bulleted_post_count += 1\n",
        "\n",
        "percent_bulleted = 100 * bulleted_post_count / df_jobs.shape[0]\n",
        "print(f\"{percent_bulleted:.2f}% of the postings contain bullets\")"
      ],
      "metadata": {
        "id": "NyciPnxZPYhs",
        "outputId": "9c5121b7-f478-4578-ea7d-54c6ab328c0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90.53% of the postings contain bullets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do all (or most) of these bullets focus on\n",
        "skills? \n",
        "\n",
        "We currently don’t know. However, we can better gauge the contents of the bullet\n",
        "points by printing the top-ranked words in their text. \n",
        "\n",
        "We can rank these words by\n",
        "occurrence count; alternatively, we can carry out the ranking using term frequencyinverse\n",
        "document frequency (TFIDF) values rather than raw counts. \n",
        "\n",
        "As we know, such TFIDF rankings are less likely to contain irrelevant words."
      ],
      "metadata": {
        "id": "XY_yGUb4T0N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Examining the top-ranked words in the HTML bullets\n",
        "def rank_words(text_list):\n",
        "  vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "  tfidf_matrix = vectorizer.fit_transform(text_list).toarray()\n",
        "  df = pd.DataFrame({\"Words\": vectorizer.get_feature_names(), \"Summed TFIDF\": tfidf_matrix.sum(axis=0)})\n",
        "  sorted_df = df.sort_values(\"Summed TFIDF\", ascending=False)\n",
        "  return sorted_df"
      ],
      "metadata": {
        "id": "7Tpj7VAaT9RJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_bullets = []\n",
        "for bullet_list in df_jobs.Bullets:\n",
        "  all_bullets.extend(bullet_list)\n",
        "\n",
        "sorted_df = rank_words(all_bullets)\n",
        "print(sorted_df[:5].to_string(index=False))"
      ],
      "metadata": {
        "id": "XP6AAgc2VC0M",
        "outputId": "5043b782-6c3c-4027-bafa-5c5e62be9941",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Words  Summed TFIDF\n",
            "experience    878.030398\n",
            "      data    842.978780\n",
            "    skills    440.780236\n",
            "      work    371.684232\n",
            "   ability    370.969638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Examining the top-ranked words in the HTML bodies\n",
        "non_bullets = []\n",
        "for soup in soup_objects:\n",
        "  body = soup.body\n",
        "  for tag in body.find_all(\"li\"):\n",
        "    tag.decompose()\n",
        "  non_bullets.append(body.text)\n",
        "\n",
        "sorted_df = rank_words(non_bullets)\n",
        "print(sorted_df[:5].to_string(index=False))"
      ],
      "metadata": {
        "id": "NNL3sOK_VepD",
        "outputId": "276d809d-b540-4a30-9131-fedd845eb238",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Words  Summed TFIDF\n",
            "      data     99.111312\n",
            "      team     39.175041\n",
            "      work     38.928948\n",
            "experience     36.820836\n",
            "  business     36.140488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking titles for references to data science positions\n",
        "regex = r\"Data Scien(ce|tist)\"\n",
        "df_non_ds_jobs = df_jobs[~df_jobs.Title.str.contains(regex, case=False)]\n",
        "\n",
        "percent_non_ds = 100 * df_non_ds_jobs.shape[0] / df_jobs.shape[0]\n",
        "print(f\"{percent_non_ds:.2f}% of the job posting titles do not mention a data science position. Below is a sample of such titles:\\n\")\n",
        "\n",
        "for title in df_non_ds_jobs.Title[:10]:\n",
        "  print(title)"
      ],
      "metadata": {
        "id": "anLFDDvgZEpn",
        "outputId": "1aa5397e-05cd-4f7d-b8eb-03ed55300eb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64.33% of the job posting titles do not mention a data science position. Below is a sample of such titles:\n",
            "\n",
            "Patient Care Assistant / PCA - Med/Surg (Fayette, AL) - Fayette, AL\n",
            "Data Manager / Analyst - Oakland, CA\n",
            "Scientific Programmer - Berkeley, CA\n",
            "JD Digits - AI Lab Research Intern - Mountain View, CA\n",
            "Operations and Technology Summer 2020 Internship-West Coast - Universal City, CA\n",
            "Data and Reporting Analyst - Olympia, WA 98501\n",
            "Senior Manager Advanced Analytics - Walmart Media Group - San Bruno, CA\n",
            "Data Specialist, Product Support Operations - Sunnyvale, CA\n",
            "Deep Learning Engineer - Westlake, TX\n",
            "Research Intern, 2020 - San Francisco, CA 94105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampling bullets from a non-data science job\n",
        "bullets = df_non_ds_jobs.Bullets.iloc[0]\n",
        "for i, bullet in enumerate(bullets):\n",
        "  print(f\"{i}: {bullet.strip()}\")"
      ],
      "metadata": {
        "id": "WSLM3V_SZ_Db",
        "outputId": "a86fb182-33b1-444e-9a70-0a375490e686",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Provides all personal care services in accordance with the plan of treatment assigned by the registered nurse\n",
            "1: Accurately documents care provided\n",
            "2: Applies safety principles and proper body mechanics to the performance of specific techniques of personal and supportive care, such as ambulation of patients, transferring patients, assisting with normal range of motions and positioning\n",
            "3: Participates in economical utilization of supplies and ensures that equipment and nursing units are maintained in a clean, safe manner\n",
            "4: Routinely follows and adheres to all policies and procedures\n",
            "5: Assists in performance improvement (PI) activities by serving on PI teams as warranted, assisting with PI measures and supporting and implementing changes necessary for improvement\n",
            "6: Maintains performance, patient and employee satisfaction and financial standards as outlined in the performance evaluation\n",
            "7: Performs compliance requirements as outlined in the Employee Handbook\n",
            "8: Must adhere to the DCH Behavioral Standards including creating positive relationships with patients/families, coworkers, colleagues and with self\n",
            "9: Requires use of electronic mail, time and attendance software, learning management software and intranet\n",
            "10: Must adhere to all DCH Health System policies and procedures\n",
            "11: All other duties as assigned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are data scientists; our primary objective isn’t patient care (index 0) or nursing equipment maintenance.\n",
        "\n",
        "We need to delete these skills from our dataset,\n",
        "but how? \n",
        "\n",
        "One approach is to use text similarity.\n",
        "\n",
        "Basically, we should evaluate the relevance of each job relative to both the resume and\n",
        "book material; this would allow us to filter the extraneous postings and retain only the\n",
        "most relevant jobs.\n",
        "\n",
        "We should accomplish our goal as follows:\n",
        "\n",
        "1. Obtain relevant job postings that partially match our existing skill set.\n",
        "2. Examine which bullet points in these postings are missing from our existing\n",
        "skill set.\n",
        "\n",
        "With this strategy in mind, we’ll now filter the jobs by relevance."
      ],
      "metadata": {
        "id": "8C-_L82hab9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Filtering jobs by relevance"
      ],
      "metadata": {
        "id": "1poVkvkIbI6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HcohWJ4pbLBi"
      }
    }
  ]
}