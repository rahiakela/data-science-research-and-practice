{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNMH9CjVtIF55WJAu6ijUTH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/data-science-research-and-practice/blob/main/feature-engineering-bookcamp/01_diagnosing_COVID_19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "bQi7slrKbeAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "np.random.seed(0)\n",
        "import random\n",
        "random.seed(0)"
      ],
      "metadata": {
        "id": "SvxNHn8Xbfha"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "#from feature_engine.imputation import EndTailImputer\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import MultiLabelBinarizer  # class to help make dummy variables\n",
        "from functools import reduce\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, mean_squared_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "1CGRZe7HboN3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_grid_search(x_train, y_train, x_test, y_test, feature_engineering_pipeline):\n",
        "    '''\n",
        "    simple helper function to grid search an ExtraTreesClassifier model and\n",
        "    print out a classification report for the best param set.\n",
        "    Best here is defined as having the best cross-validated accuracy on the training set\n",
        "    '''\n",
        "\n",
        "    params = {  # some simple parameters to grid search\n",
        "        'max_depth': [10, None],\n",
        "        'n_estimators': [10, 50, 100, 500],\n",
        "        'criterion': ['gini', 'entropy']\n",
        "    }\n",
        "\n",
        "    base_model = ExtraTreesClassifier()\n",
        "\n",
        "    model_grid_search = GridSearchCV(base_model, param_grid=params, cv=3)\n",
        "    start_time = time.time()  # capture the start time\n",
        "    if feature_engineering_pipeline:  # fit FE pipeline to training data and use it to transform test data\n",
        "        parsed_x_train = feature_engineering_pipeline.fit_transform(x_train, y_train)\n",
        "        parsed_x_test = feature_engineering_pipeline.transform(x_test)\n",
        "    else:\n",
        "        parsed_x_train = x_train\n",
        "        parsed_x_test = x_test\n",
        "\n",
        "    parse_time = time.time()\n",
        "    print(f\"Parsing took {(parse_time - start_time):.2f} seconds\")\n",
        "\n",
        "    model_grid_search.fit(parsed_x_train, y_train)\n",
        "    fit_time = time.time()\n",
        "    print(f\"Training took {(fit_time - start_time):.2f} seconds\")\n",
        "\n",
        "    best_model = model_grid_search.best_estimator_\n",
        "\n",
        "    print(classification_report(y_true=y_test, y_pred=best_model.predict(parsed_x_test)))\n",
        "    end_time = time.time()\n",
        "    print(f\"Overall took {(end_time - start_time):.2f} seconds\")\n",
        "\n",
        "    return best_model"
      ],
      "metadata": {
        "id": "Vq9ih3Vsbqfr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EDA"
      ],
      "metadata": {
        "id": "NzxCXwnsc26Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "covid_flu = pd.read_csv(\"\")"
      ],
      "metadata": {
        "id": "L3ths0euc4E5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}